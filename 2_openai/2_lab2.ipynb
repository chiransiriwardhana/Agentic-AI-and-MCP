{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 2 Day 2\n",
    "\n",
    "Our first Agentic Framework project!!\n",
    "\n",
    "Prepare yourself for something ridiculously easy.\n",
    "\n",
    "We're going to build a simple Agent system for generating cold sales outreach emails:\n",
    "1. Agent workflow\n",
    "2. Use of tools to call functions\n",
    "3. Agent collaboration via Tools and Handoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we start - some setup:\n",
    "\n",
    "\n",
    "Please visit Sendgrid at: https://sendgrid.com/\n",
    "\n",
    "(Sendgrid is a Twilio company for sending emails.)\n",
    "\n",
    "If SendGrid gives you problems, see the alternative implementation using \"Resend Email\" in community_contributions/2_lab2_with_resend_email\n",
    "\n",
    "Please set up an account - it's free! (at least, for me, right now).\n",
    "\n",
    "Once you've created an account, click on:\n",
    "\n",
    "Settings (left sidebar) >> API Keys >> Create API Key (button on top right)\n",
    "\n",
    "Copy the key to the clipboard, then add a new line to your .env file:\n",
    "\n",
    "`SENDGRID_API_KEY=xxxx`\n",
    "\n",
    "And also, within SendGrid, go to:\n",
    "\n",
    "Settings (left sidebar) >> Sender Authentication >> \"Verify a Single Sender\"  \n",
    "and verify that your own email address is a real email address, so that SendGrid can send emails for you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from agents import Agent, Runner, trace, function_tool\n",
    "from openai.types.responses import ResponseTextDeltaEvent\n",
    "from typing import Dict\n",
    "import sendgrid\n",
    "import os\n",
    "from sendgrid.helpers.mail import Mail, Email, To, Content\n",
    "import asyncio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n"
     ]
    }
   ],
   "source": [
    "# Let's just check emails are working for you\n",
    "\n",
    "def send_test_email():\n",
    "    sg = sendgrid.SendGridAPIClient(api_key=os.environ.get('SENDGRID_API_KEY'))\n",
    "    from_email = Email(\"chiransiriwardhana.17@cse.mrt.ac.lk\")  # Change to your verified sender\n",
    "    to_email = To(\"chiranchathwara16@gmail.com\")  # Change to your recipient\n",
    "    content = Content(\"text/plain\", \"This is an important test email\")\n",
    "    mail = Mail(from_email, to_email, \"Test email\", content).get()\n",
    "    response = sg.client.mail.send.post(request_body=mail)\n",
    "    print(response.status_code)\n",
    "\n",
    "send_test_email()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Did you receive the test email\n",
    "\n",
    "If you get a 202, then you're good to go!\n",
    "\n",
    "#### Certificate error\n",
    "\n",
    "If you get an error SSL: CERTIFICATE_VERIFY_FAILED then students Chris S and Oleksandr K have suggestions:  \n",
    "First run this: `!uv pip install --upgrade certifi`  \n",
    "Next, run this:\n",
    "```python\n",
    "import certifi\n",
    "import os\n",
    "os.environ['SSL_CERT_FILE'] = certifi.where()\n",
    "```\n",
    "\n",
    "#### Other errors or no email\n",
    "\n",
    "If there are other problems, you'll need to check your API key and your verified sender email address in the SendGrid dashboard\n",
    "\n",
    "Or use the alternative implementation using \"Resend Email\" in community_contributions/2_lab2_with_resend_email\n",
    "\n",
    "(Or - you could always replace the email sending code below with a Pushover call, or something to simply write to a flat file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Agent workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions1 = \"You are a sales agent working for ComplAI, \\\n",
    "a company that provides a SaaS tool for ensuring SOC2 compliance and preparing for audits, powered by AI. \\\n",
    "You write professional, serious cold emails.\"\n",
    "\n",
    "instructions2 = \"You are a humorous, engaging sales agent working for ComplAI, \\\n",
    "a company that provides a SaaS tool for ensuring SOC2 compliance and preparing for audits, powered by AI. \\\n",
    "You write witty, engaging cold emails that are likely to get a response.\"\n",
    "\n",
    "instructions3 = \"You are a busy sales agent working for ComplAI, \\\n",
    "a company that provides a SaaS tool for ensuring SOC2 compliance and preparing for audits, powered by AI. \\\n",
    "You write concise, to the point cold emails.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_agent1 = Agent(\n",
    "        name=\"Professional Sales Agent\",\n",
    "        instructions=instructions1,\n",
    "        model=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "sales_agent2 = Agent(\n",
    "        name=\"Engaging Sales Agent\",\n",
    "        instructions=instructions2,\n",
    "        model=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "sales_agent3 = Agent(\n",
    "        name=\"Busy Sales Agent\",\n",
    "        instructions=instructions3,\n",
    "        model=\"gpt-4o-mini\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Simplify Your SOC2 Compliance Process with ComplAI\n",
      "\n",
      "Dear [Recipient's Name],\n",
      "\n",
      "I hope this message finds you well.\n",
      "\n",
      "I‚Äôm [Your Name], a representative from ComplAI. We specialize in streamlining the SOC2 compliance process through our advanced AI-powered SaaS tool. As you know, achieving and maintaining SOC2 compliance can be time-consuming and complex, often pulling valuable resources away from core business functions.\n",
      "\n",
      "At ComplAI, we offer a solution that not only simplifies compliance preparation but also optimizes the audit process. Our platform provides real-time insights, automated documentation, and tailored support, allowing you to focus on what you do best‚Äîgrowing your business.\n",
      "\n",
      "I would appreciate the opportunity to discuss how ComplAI can help your organization enhance its compliance efforts while reducing overhead costs. Would you be available for a brief call next week?\n",
      "\n",
      "Thank you for considering this opportunity. I look forward to your response.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]  \n",
      "[Your Position]  \n",
      "ComplAI  \n",
      "[Your Phone Number]  \n",
      "[Your Email Address]  \n",
      "[Website URL]  "
     ]
    }
   ],
   "source": [
    "\n",
    "result = Runner.run_streamed(sales_agent1, input=\"Write a cold sales email\")\n",
    "async for event in result.stream_events():\n",
    "    if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
    "        print(event.data.delta, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Simplify Your SOC 2 Compliance Process\n",
      "\n",
      "Dear [Recipient's Name],\n",
      "\n",
      "I hope this message finds you well. My name is [Your Name], and I‚Äôm reaching out to introduce you to ComplAI, a cutting-edge SaaS solution designed specifically to streamline SOC 2 compliance and audit preparation.\n",
      "\n",
      "In today‚Äôs fast-paced environment, maintaining compliance can be a daunting task. ComplAI leverages advanced AI technology to simplify the complexities associated with SOC 2 requirements. Our platform not only automates documentation and evidence collection but also provides real-time monitoring to help ensure your organization stays compliant and audit-ready.\n",
      "\n",
      "Here are a few key benefits of using ComplAI:\n",
      "\n",
      "- **Efficiency**: Reduce the time and resources needed to prepare for audits.\n",
      "- **Accuracy**: Minimize human error with automated data verification processes.\n",
      "- **Scalability**: Adapt our platform to fit the unique needs of your organization as it grows.\n",
      "\n",
      "I would love the opportunity to discuss how ComplAI can specifically benefit [Recipient's Company Name]. Would you be available for a brief call next week?\n",
      "\n",
      "Thank you for considering this opportunity. I look forward to hearing from you.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]  \n",
      "[Your Position]  \n",
      "ComplAI  \n",
      "[Your Phone Number]  \n",
      "[Your Email]  \n",
      "[Company Website]  \n",
      "\n",
      "\n",
      "Subject: Is Your SOC2 Compliance Scaring You? üéÉ\n",
      "\n",
      "Hi [Recipient's Name],\n",
      "\n",
      "I hope this email finds you enjoying a coffee that‚Äôs as strong as your desire for SOC2 compliance! ‚òïÔ∏è\n",
      "\n",
      "Let‚Äôs face it: preparing for audits can feel like preparing for a horror movie - one minute you're feeling fine, and the next, you find yourself facing the terrifying specter of non-compliance! üò± \n",
      "\n",
      "That‚Äôs where ComplAI swoops in like a superhero in spandex ‚Äî without the awkward costumes! Our AI-powered SaaS tool takes the fear out of SOC2 audits, helping you streamline compliance with a sprinkle of wit and zero scare tactics. \n",
      "\n",
      "Imagine turning your compliance nightmare into a walk in the park (with puppies, of course)! üêæ We help automate processes, track requirements, and prep you for audits faster than you can say ‚Äúlet‚Äôs not do this the old way.‚Äù\n",
      "\n",
      "Are you ready to banish those audit gremlins? Let‚Äôs chat and turn that daunting SOC2 compliance process into a piece of cake. üéÇ\n",
      "\n",
      "Looking forward to your response!\n",
      "\n",
      "Best,  \n",
      "[Your Name]  \n",
      "[Your Job Title]  \n",
      "ComplAI  \n",
      "[Your Contact Information]  \n",
      "\n",
      "P.S. Did I mention that fewer headaches and more coffee breaks come standard with our solution? üòâ\n",
      "\n",
      "\n",
      "Subject: Simplify Your SOC2 Compliance Process\n",
      "\n",
      "Hi [Recipient's Name],\n",
      "\n",
      "I hope this message finds you well. I‚Äôm reaching out from ComplAI, where we help companies like yours streamline SOC2 compliance using our AI-powered SaaS tool.\n",
      "\n",
      "Whether you‚Äôre preparing for an audit or just looking to enhance your compliance processes, our solution can save you time and reduce stress.\n",
      "\n",
      "Would you be open to a quick call next week to explore how we can support your compliance efforts?\n",
      "\n",
      "Best regards,  \n",
      "[Your Name]  \n",
      "[Your Job Title]  \n",
      "ComplAI  \n",
      "[Your Phone Number]  \n",
      "[Your LinkedIn Profile]  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "message = \"Write a cold sales email\"\n",
    "\n",
    "with trace(\"Parallel cold emails\"):\n",
    "    results = await asyncio.gather(\n",
    "        Runner.run(sales_agent1, message),\n",
    "        Runner.run(sales_agent2, message),\n",
    "        Runner.run(sales_agent3, message),\n",
    "    )\n",
    "\n",
    "outputs = [result.final_output for result in results]\n",
    "\n",
    "for output in outputs:\n",
    "    print(output + \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_picker = Agent(\n",
    "    name=\"sales_picker\",\n",
    "    instructions=\"You pick the best cold sales email from the given options. \\\n",
    "Imagine you are a customer and pick the one you are most likely to respond to. \\\n",
    "Do not give an explanation; reply with the selected email only.\",\n",
    "    model=\"gpt-4o-mini\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best sales email:\n",
      "Subject: Say Goodbye to Audit Anxiety‚ÄîComplAI is Here to Save the Day! üåü\n",
      "\n",
      "Hey [Recipient's Name],\n",
      "\n",
      "Ever felt like preparing for an audit is akin to summoning the spirit of a cranky accountant? üôà Fear not! At ComplAI, we‚Äôve got the perfect potion to turn that dread into delight.\n",
      "\n",
      "Imagine a world where SOC2 compliance feels less like navigating a labyrinth and more like a leisurely stroll in the park. Our AI-powered tool is like a magic wand (abracadabra!) that simplifies the entire process, ensuring you‚Äôre always audit-ready with just a sprinkle of pixie dust. ü™Ñ\n",
      "\n",
      "Why choose ComplAI? \n",
      "\n",
      "1. **Automated Everything**: Wave goodbye to manual checklists! Our AI does the heavy lifting while you sip your coffee. ‚òï\n",
      "   \n",
      "2. **Expert Guidance**: Think of us as your trusty sidekick‚ÄîBatman didn‚Äôt do it alone, right? ü¶∏‚Äç‚ôÇÔ∏è\n",
      "\n",
      "3. **Fast & Friendly**: We‚Äôre as quick as a cheetah on espresso, and we promise we won‚Äôt bite once you get to know us!\n",
      "\n",
      "Let‚Äôs chat about how we can turn your compliance woes into compliance wows! Can we schedule a quick call this week? I promise to keep the accountant ghost at bay! üëª\n",
      "\n",
      "Cheers,  \n",
      "[Your Name]  \n",
      "ComplAI | The Friendly Audit Sidekick  \n",
      "[Your Phone Number]  \n",
      "[Your LinkedIn (if applicable)]  \n",
      "\n",
      "P.S. We offer a free demo‚Äîno strings attached! Just pure compliance magic. ‚ú®\n"
     ]
    }
   ],
   "source": [
    "message = \"Write a cold sales email\"\n",
    "\n",
    "with trace(\"Selection from sales people\"):\n",
    "    results = await asyncio.gather(\n",
    "        Runner.run(sales_agent1, message),\n",
    "        Runner.run(sales_agent2, message),\n",
    "        Runner.run(sales_agent3, message),\n",
    "    )\n",
    "    outputs = [result.final_output for result in results]\n",
    "\n",
    "    emails = \"Cold sales emails:\\n\\n\" + \"\\n\\nEmail:\\n\\n\".join(outputs)\n",
    "\n",
    "    best = await Runner.run(sales_picker, emails)\n",
    "\n",
    "    print(f\"Best sales email:\\n{best.final_output}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go and check out the trace:\n",
    "\n",
    "https://platform.openai.com/traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: use of tools\n",
    "\n",
    "Now we will add a tool to the mix.\n",
    "\n",
    "Remember all that json boilerplate and the `handle_tool_calls()` function with the if logic.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_agent1 = Agent(\n",
    "        name=\"Professional Sales Agent\",\n",
    "        instructions=instructions1,\n",
    "        model=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "sales_agent2 = Agent(\n",
    "        name=\"Engaging Sales Agent\",\n",
    "        instructions=instructions2,\n",
    "        model=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "sales_agent3 = Agent(\n",
    "        name=\"Busy Sales Agent\",\n",
    "        instructions=instructions3,\n",
    "        model=\"gpt-4o-mini\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Agent(name='Professional Sales Agent', handoff_description=None, tools=[], mcp_servers=[], mcp_config={}, instructions='You are a sales agent working for ComplAI, a company that provides a SaaS tool for ensuring SOC2 compliance and preparing for audits, powered by AI. You write professional, serious cold emails.', prompt=None, handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, prompt_cache_retention=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_agent1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps 2 and 3: Tools and Agent interactions\n",
    "\n",
    "Remember all that boilerplate json?\n",
    "\n",
    "Simply wrap your function with the decorator `@function_tool`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def send_email(body: str):\n",
    "    \"\"\" Send out an email with the given body to all sales prospects \"\"\"\n",
    "    sg = sendgrid.SendGridAPIClient(api_key=os.environ.get('SENDGRID_API_KEY'))\n",
    "    from_email = Email(\"ed@edwarddonner.com\")  # Change to your verified sender\n",
    "    to_email = To(\"ed.donner@gmail.com\")  # Change to your recipient\n",
    "    content = Content(\"text/plain\", body)\n",
    "    mail = Mail(from_email, to_email, \"Sales email\", content).get()\n",
    "    sg.client.mail.send.post(request_body=mail)\n",
    "    return {\"status\": \"success\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This has automatically been converted into a tool, with the boilerplate json created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionTool(name='send_email', description='Send out an email with the given body to all sales prospects', params_json_schema={'properties': {'body': {'title': 'Body', 'type': 'string'}}, 'required': ['body'], 'title': 'send_email_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x13144af80>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at it\n",
    "send_email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And you can also convert an Agent into a tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionTool(name='sales_agent1', description='Write a cold sales email', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'sales_agent1_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x13144b370>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool1 = sales_agent1.as_tool(tool_name=\"sales_agent1\", tool_description=\"Write a cold sales email\")\n",
    "tool1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So now we can gather all the tools together:\n",
    "\n",
    "A tool for each of our 3 email-writing agents\n",
    "\n",
    "And a tool for our function to send emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FunctionTool(name='sales_agent1', description='Write a cold sales email', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'sales_agent1_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x131039090>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None),\n",
       " FunctionTool(name='sales_agent2', description='Write a cold sales email', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'sales_agent2_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x13103a290>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None),\n",
       " FunctionTool(name='sales_agent3', description='Write a cold sales email', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'sales_agent3_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x127c29510>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None),\n",
       " FunctionTool(name='send_email', description='Send out an email with the given body to all sales prospects', params_json_schema={'properties': {'body': {'title': 'Body', 'type': 'string'}}, 'required': ['body'], 'title': 'send_email_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x13144af80>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = \"Write a cold sales email\"\n",
    "\n",
    "tool1 = sales_agent1.as_tool(tool_name=\"sales_agent1\", tool_description=description)\n",
    "tool2 = sales_agent2.as_tool(tool_name=\"sales_agent2\", tool_description=description)\n",
    "tool3 = sales_agent3.as_tool(tool_name=\"sales_agent3\", tool_description=description)\n",
    "\n",
    "tools = [tool1, tool2, tool3, send_email]\n",
    "\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now it's time for our Sales Manager - our planning agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error getting response: Error code: 400 - {'error': {'message': \"The requested model 'llama3.2' does not exist.\", 'type': 'invalid_request_error', 'param': 'model', 'code': 'model_not_found'}}. (request_id: req_5335dbd4b4cc475095fc539d311e158e)\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"The requested model 'llama3.2' does not exist.\", 'type': 'invalid_request_error', 'param': 'model', 'code': 'model_not_found'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSend a cold sales email addressed to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDear CEO\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSales manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 24\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m Runner\u001b[38;5;241m.\u001b[39mrun(sales_manager, message)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.10/site-packages/agents/run.py:372\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(cls, starting_agent, input, context, max_turns, hooks, run_config, previous_response_id, auto_previous_response_id, conversation_id, session)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03mRun a workflow starting at the given agent.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;124;03m    type of the output.\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    371\u001b[0m runner \u001b[38;5;241m=\u001b[39m DEFAULT_AGENT_RUNNER\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m    373\u001b[0m     starting_agent,\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    375\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[1;32m    376\u001b[0m     max_turns\u001b[38;5;241m=\u001b[39mmax_turns,\n\u001b[1;32m    377\u001b[0m     hooks\u001b[38;5;241m=\u001b[39mhooks,\n\u001b[1;32m    378\u001b[0m     run_config\u001b[38;5;241m=\u001b[39mrun_config,\n\u001b[1;32m    379\u001b[0m     previous_response_id\u001b[38;5;241m=\u001b[39mprevious_response_id,\n\u001b[1;32m    380\u001b[0m     auto_previous_response_id\u001b[38;5;241m=\u001b[39mauto_previous_response_id,\n\u001b[1;32m    381\u001b[0m     conversation_id\u001b[38;5;241m=\u001b[39mconversation_id,\n\u001b[1;32m    382\u001b[0m     session\u001b[38;5;241m=\u001b[39msession,\n\u001b[1;32m    383\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.10/site-packages/agents/run.py:671\u001b[0m, in \u001b[0;36mAgentRunner.run\u001b[0;34m(self, starting_agent, input, **kwargs)\u001b[0m\n\u001b[1;32m    663\u001b[0m     sequential_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_input_guardrails(\n\u001b[1;32m    664\u001b[0m         starting_agent,\n\u001b[1;32m    665\u001b[0m         sequential_guardrails,\n\u001b[1;32m    666\u001b[0m         _copy_str_or_list(prepared_input),\n\u001b[1;32m    667\u001b[0m         context_wrapper,\n\u001b[1;32m    668\u001b[0m     )\n\u001b[1;32m    670\u001b[0m \u001b[38;5;66;03m# Run parallel guardrails + agent together.\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m input_guardrail_results, turn_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_input_guardrails(\n\u001b[1;32m    673\u001b[0m         starting_agent,\n\u001b[1;32m    674\u001b[0m         parallel_guardrails,\n\u001b[1;32m    675\u001b[0m         _copy_str_or_list(prepared_input),\n\u001b[1;32m    676\u001b[0m         context_wrapper,\n\u001b[1;32m    677\u001b[0m     ),\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_single_turn(\n\u001b[1;32m    679\u001b[0m         agent\u001b[38;5;241m=\u001b[39mcurrent_agent,\n\u001b[1;32m    680\u001b[0m         all_tools\u001b[38;5;241m=\u001b[39mall_tools,\n\u001b[1;32m    681\u001b[0m         original_input\u001b[38;5;241m=\u001b[39moriginal_input,\n\u001b[1;32m    682\u001b[0m         generated_items\u001b[38;5;241m=\u001b[39mgenerated_items,\n\u001b[1;32m    683\u001b[0m         hooks\u001b[38;5;241m=\u001b[39mhooks,\n\u001b[1;32m    684\u001b[0m         context_wrapper\u001b[38;5;241m=\u001b[39mcontext_wrapper,\n\u001b[1;32m    685\u001b[0m         run_config\u001b[38;5;241m=\u001b[39mrun_config,\n\u001b[1;32m    686\u001b[0m         should_run_agent_start_hooks\u001b[38;5;241m=\u001b[39mshould_run_agent_start_hooks,\n\u001b[1;32m    687\u001b[0m         tool_use_tracker\u001b[38;5;241m=\u001b[39mtool_use_tracker,\n\u001b[1;32m    688\u001b[0m         server_conversation_tracker\u001b[38;5;241m=\u001b[39mserver_conversation_tracker,\n\u001b[1;32m    689\u001b[0m     ),\n\u001b[1;32m    690\u001b[0m )\n\u001b[1;32m    692\u001b[0m \u001b[38;5;66;03m# Combine sequential and parallel results.\u001b[39;00m\n\u001b[1;32m    693\u001b[0m input_guardrail_results \u001b[38;5;241m=\u001b[39m sequential_results \u001b[38;5;241m+\u001b[39m input_guardrail_results\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.10/site-packages/agents/run.py:1689\u001b[0m, in \u001b[0;36mAgentRunner._run_single_turn\u001b[0;34m(cls, agent, all_tools, original_input, generated_items, hooks, context_wrapper, run_config, should_run_agent_start_hooks, tool_use_tracker, server_conversation_tracker)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m ItemHelpers\u001b[38;5;241m.\u001b[39minput_to_new_input_list(original_input)\n\u001b[1;32m   1687\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mextend([generated_item\u001b[38;5;241m.\u001b[39mto_input_item() \u001b[38;5;28;01mfor\u001b[39;00m generated_item \u001b[38;5;129;01min\u001b[39;00m generated_items])\n\u001b[0;32m-> 1689\u001b[0m new_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_new_response(\n\u001b[1;32m   1690\u001b[0m     agent,\n\u001b[1;32m   1691\u001b[0m     system_prompt,\n\u001b[1;32m   1692\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1693\u001b[0m     output_schema,\n\u001b[1;32m   1694\u001b[0m     all_tools,\n\u001b[1;32m   1695\u001b[0m     handoffs,\n\u001b[1;32m   1696\u001b[0m     hooks,\n\u001b[1;32m   1697\u001b[0m     context_wrapper,\n\u001b[1;32m   1698\u001b[0m     run_config,\n\u001b[1;32m   1699\u001b[0m     tool_use_tracker,\n\u001b[1;32m   1700\u001b[0m     server_conversation_tracker,\n\u001b[1;32m   1701\u001b[0m     prompt_config,\n\u001b[1;32m   1702\u001b[0m )\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_single_step_result_from_response(\n\u001b[1;32m   1705\u001b[0m     agent\u001b[38;5;241m=\u001b[39magent,\n\u001b[1;32m   1706\u001b[0m     original_input\u001b[38;5;241m=\u001b[39moriginal_input,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1715\u001b[0m     tool_use_tracker\u001b[38;5;241m=\u001b[39mtool_use_tracker,\n\u001b[1;32m   1716\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.10/site-packages/agents/run.py:1952\u001b[0m, in \u001b[0;36mAgentRunner._get_new_response\u001b[0;34m(cls, agent, system_prompt, input, output_schema, all_tools, handoffs, hooks, context_wrapper, run_config, tool_use_tracker, server_conversation_tracker, prompt_config)\u001b[0m\n\u001b[1;32m   1942\u001b[0m previous_response_id \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1943\u001b[0m     server_conversation_tracker\u001b[38;5;241m.\u001b[39mprevious_response_id\n\u001b[1;32m   1944\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m server_conversation_tracker\n\u001b[1;32m   1945\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m server_conversation_tracker\u001b[38;5;241m.\u001b[39mprevious_response_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1946\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m )\n\u001b[1;32m   1948\u001b[0m conversation_id \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1949\u001b[0m     server_conversation_tracker\u001b[38;5;241m.\u001b[39mconversation_id \u001b[38;5;28;01mif\u001b[39;00m server_conversation_tracker \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m )\n\u001b[0;32m-> 1952\u001b[0m new_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m model\u001b[38;5;241m.\u001b[39mget_response(\n\u001b[1;32m   1953\u001b[0m     system_instructions\u001b[38;5;241m=\u001b[39mfiltered\u001b[38;5;241m.\u001b[39minstructions,\n\u001b[1;32m   1954\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mfiltered\u001b[38;5;241m.\u001b[39minput,\n\u001b[1;32m   1955\u001b[0m     model_settings\u001b[38;5;241m=\u001b[39mmodel_settings,\n\u001b[1;32m   1956\u001b[0m     tools\u001b[38;5;241m=\u001b[39mall_tools,\n\u001b[1;32m   1957\u001b[0m     output_schema\u001b[38;5;241m=\u001b[39moutput_schema,\n\u001b[1;32m   1958\u001b[0m     handoffs\u001b[38;5;241m=\u001b[39mhandoffs,\n\u001b[1;32m   1959\u001b[0m     tracing\u001b[38;5;241m=\u001b[39mget_model_tracing_impl(\n\u001b[1;32m   1960\u001b[0m         run_config\u001b[38;5;241m.\u001b[39mtracing_disabled, run_config\u001b[38;5;241m.\u001b[39mtrace_include_sensitive_data\n\u001b[1;32m   1961\u001b[0m     ),\n\u001b[1;32m   1962\u001b[0m     previous_response_id\u001b[38;5;241m=\u001b[39mprevious_response_id,\n\u001b[1;32m   1963\u001b[0m     conversation_id\u001b[38;5;241m=\u001b[39mconversation_id,\n\u001b[1;32m   1964\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mprompt_config,\n\u001b[1;32m   1965\u001b[0m )\n\u001b[1;32m   1967\u001b[0m context_wrapper\u001b[38;5;241m.\u001b[39musage\u001b[38;5;241m.\u001b[39madd(new_response\u001b[38;5;241m.\u001b[39musage)\n\u001b[1;32m   1969\u001b[0m \u001b[38;5;66;03m# If we have run hooks, or if the agent has hooks, we need to call them after the LLM call\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.10/site-packages/agents/models/openai_responses.py:97\u001b[0m, in \u001b[0;36mOpenAIResponsesModel.get_response\u001b[0;34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, tracing, previous_response_id, conversation_id, prompt)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m response_span(disabled\u001b[38;5;241m=\u001b[39mtracing\u001b[38;5;241m.\u001b[39mis_disabled()) \u001b[38;5;28;01mas\u001b[39;00m span_response:\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetch_response(\n\u001b[1;32m     98\u001b[0m             system_instructions,\n\u001b[1;32m     99\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    100\u001b[0m             model_settings,\n\u001b[1;32m    101\u001b[0m             tools,\n\u001b[1;32m    102\u001b[0m             output_schema,\n\u001b[1;32m    103\u001b[0m             handoffs,\n\u001b[1;32m    104\u001b[0m             previous_response_id\u001b[38;5;241m=\u001b[39mprevious_response_id,\n\u001b[1;32m    105\u001b[0m             conversation_id\u001b[38;5;241m=\u001b[39mconversation_id,\n\u001b[1;32m    106\u001b[0m             stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    107\u001b[0m             prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m    108\u001b[0m         )\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _debug\u001b[38;5;241m.\u001b[39mDONT_LOG_MODEL_DATA:\n\u001b[1;32m    111\u001b[0m             logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLM responded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.10/site-packages/agents/models/openai_responses.py:320\u001b[0m, in \u001b[0;36mOpenAIResponsesModel._fetch_response\u001b[0;34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, previous_response_id, conversation_id, stream, prompt)\u001b[0m\n\u001b[1;32m    316\u001b[0m         response_format \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbosity\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_settings\u001b[38;5;241m.\u001b[39mverbosity}\n\u001b[1;32m    318\u001b[0m stream_param: Literal[\u001b[38;5;28;01mTrue\u001b[39;00m] \u001b[38;5;241m|\u001b[39m Omit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m omit\n\u001b[0;32m--> 320\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mresponses\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    321\u001b[0m     previous_response_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_null_or_omit(previous_response_id),\n\u001b[1;32m    322\u001b[0m     conversation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_null_or_omit(conversation_id),\n\u001b[1;32m    323\u001b[0m     instructions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_null_or_omit(system_instructions),\n\u001b[1;32m    324\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel_param,\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mlist_input,\n\u001b[1;32m    326\u001b[0m     include\u001b[38;5;241m=\u001b[39minclude,\n\u001b[1;32m    327\u001b[0m     tools\u001b[38;5;241m=\u001b[39mtools_param,\n\u001b[1;32m    328\u001b[0m     prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_null_or_omit(prompt),\n\u001b[1;32m    329\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_null_or_omit(model_settings\u001b[38;5;241m.\u001b[39mtemperature),\n\u001b[1;32m    330\u001b[0m     top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_null_or_omit(model_settings\u001b[38;5;241m.\u001b[39mtop_p),\n\u001b[1;32m    331\u001b[0m     truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_null_or_omit(model_settings\u001b[38;5;241m.\u001b[39mtruncation),\n\u001b[1;32m    332\u001b[0m     max_output_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_null_or_omit(model_settings\u001b[38;5;241m.\u001b[39mmax_tokens),\n\u001b[1;32m    333\u001b[0m     tool_choice\u001b[38;5;241m=\u001b[39mtool_choice,\n\u001b[1;32m    334\u001b[0m     parallel_tool_calls\u001b[38;5;241m=\u001b[39mparallel_tool_calls,\n\u001b[1;32m    335\u001b[0m     stream\u001b[38;5;241m=\u001b[39mcast(Any, stream_param),\n\u001b[1;32m    336\u001b[0m     extra_headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_headers(model_settings),\n\u001b[1;32m    337\u001b[0m     extra_query\u001b[38;5;241m=\u001b[39mmodel_settings\u001b[38;5;241m.\u001b[39mextra_query,\n\u001b[1;32m    338\u001b[0m     extra_body\u001b[38;5;241m=\u001b[39mmodel_settings\u001b[38;5;241m.\u001b[39mextra_body,\n\u001b[1;32m    339\u001b[0m     text\u001b[38;5;241m=\u001b[39mresponse_format,\n\u001b[1;32m    340\u001b[0m     store\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_null_or_omit(model_settings\u001b[38;5;241m.\u001b[39mstore),\n\u001b[1;32m    341\u001b[0m     prompt_cache_retention\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_null_or_omit(model_settings\u001b[38;5;241m.\u001b[39mprompt_cache_retention),\n\u001b[1;32m    342\u001b[0m     reasoning\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_null_or_omit(model_settings\u001b[38;5;241m.\u001b[39mreasoning),\n\u001b[1;32m    343\u001b[0m     metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_null_or_omit(model_settings\u001b[38;5;241m.\u001b[39mmetadata),\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_args,\n\u001b[1;32m    345\u001b[0m )\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(Union[Response, AsyncStream[ResponseStreamEvent]], response)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.10/site-packages/openai/resources/responses/responses.py:2476\u001b[0m, in \u001b[0;36mAsyncResponses.create\u001b[0;34m(self, background, conversation, include, input, instructions, max_output_tokens, max_tool_calls, metadata, model, parallel_tool_calls, previous_response_id, prompt, prompt_cache_key, prompt_cache_retention, reasoning, safety_identifier, service_tier, store, stream, stream_options, temperature, text, tool_choice, tools, top_logprobs, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   2438\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m   2439\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2440\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2474\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m not_given,\n\u001b[1;32m   2475\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response \u001b[38;5;241m|\u001b[39m AsyncStream[ResponseStreamEvent]:\n\u001b[0;32m-> 2476\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m   2477\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/responses\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2478\u001b[0m         body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[1;32m   2479\u001b[0m             {\n\u001b[1;32m   2480\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackground\u001b[39m\u001b[38;5;124m\"\u001b[39m: background,\n\u001b[1;32m   2481\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconversation\u001b[39m\u001b[38;5;124m\"\u001b[39m: conversation,\n\u001b[1;32m   2482\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude\u001b[39m\u001b[38;5;124m\"\u001b[39m: include,\n\u001b[1;32m   2483\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2484\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstructions\u001b[39m\u001b[38;5;124m\"\u001b[39m: instructions,\n\u001b[1;32m   2485\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_output_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_output_tokens,\n\u001b[1;32m   2486\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tool_calls,\n\u001b[1;32m   2487\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m   2488\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m   2489\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[1;32m   2490\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprevious_response_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: previous_response_id,\n\u001b[1;32m   2491\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt,\n\u001b[1;32m   2492\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_cache_key\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt_cache_key,\n\u001b[1;32m   2493\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_cache_retention\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt_cache_retention,\n\u001b[1;32m   2494\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning,\n\u001b[1;32m   2495\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msafety_identifier\u001b[39m\u001b[38;5;124m\"\u001b[39m: safety_identifier,\n\u001b[1;32m   2496\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[1;32m   2497\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[1;32m   2498\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m   2499\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[1;32m   2500\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m   2501\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: text,\n\u001b[1;32m   2502\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[1;32m   2503\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[1;32m   2504\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[1;32m   2505\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m   2506\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtruncation\u001b[39m\u001b[38;5;124m\"\u001b[39m: truncation,\n\u001b[1;32m   2507\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[1;32m   2508\u001b[0m             },\n\u001b[1;32m   2509\u001b[0m             response_create_params\u001b[38;5;241m.\u001b[39mResponseCreateParamsStreaming\n\u001b[1;32m   2510\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[1;32m   2511\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m response_create_params\u001b[38;5;241m.\u001b[39mResponseCreateParamsNonStreaming,\n\u001b[1;32m   2512\u001b[0m         ),\n\u001b[1;32m   2513\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m   2514\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m   2515\u001b[0m         ),\n\u001b[1;32m   2516\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mResponse,\n\u001b[1;32m   2517\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   2518\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mAsyncStream[ResponseStreamEvent],\n\u001b[1;32m   2519\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.10/site-packages/openai/_base_client.py:1794\u001b[0m, in \u001b[0;36mAsyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1781\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1782\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1789\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1790\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _AsyncStreamT:\n\u001b[1;32m   1791\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1792\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1793\u001b[0m     )\n\u001b[0;32m-> 1794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.10/site-packages/openai/_base_client.py:1594\u001b[0m, in \u001b[0;36mAsyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1591\u001b[0m             \u001b[38;5;28;01mawait\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39maread()\n\u001b[1;32m   1593\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1594\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1596\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1598\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"The requested model 'llama3.2' does not exist.\", 'type': 'invalid_request_error', 'param': 'model', 'code': 'model_not_found'}}"
     ]
    }
   ],
   "source": [
    "# Improved instructions thanks to student Guillermo F.\n",
    "\n",
    "instructions = \"\"\"\n",
    "You are a Sales Manager at ComplAI. Your goal is to find the single best cold sales email using the sales_agent tools.\n",
    " \n",
    "Follow these steps carefully:\n",
    "1. Generate Drafts: Use all three sales_agent tools to generate three different email drafts. Do not proceed until all three drafts are ready.\n",
    " \n",
    "2. Evaluate and Select: Review the drafts and choose the single best email using your judgment of which one is most effective.\n",
    " \n",
    "3. Use the send_email tool to send the best email (and only the best email) to the user.\n",
    " \n",
    "Crucial Rules:\n",
    "- You must use the sales agent tools to generate the drafts ‚Äî do not write them yourself.\n",
    "- You must send ONE email using the send_email tool ‚Äî never more than one.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "sales_manager = Agent(name=\"Sales Manager\", instructions=instructions, tools=tools, model=\"llama3.2\")\n",
    "\n",
    "message = \"Send a cold sales email addressed to 'Dear CEO'\"\n",
    "\n",
    "with trace(\"Sales manager\"):\n",
    "    result = await Runner.run(sales_manager, message)\n",
    "\n",
    "\n",
    "# from langchain_ollama import OllamaLLM\n",
    "# from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "# llm = OllamaLLM(model=\"llama3.2\")\n",
    "\n",
    "# agent = initialize_agent(\n",
    "#     tools=[],\n",
    "#     llm=llm,\n",
    "#     agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "# agent.run(\"Send a cold sales email addressed to 'Dear CEO'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Wait - you didn't get an email??</h2>\n",
    "            <span style=\"color:#ff7800;\">With much thanks to student Chris S. for describing his issue and fixes. \n",
    "            If you don't receive an email after running the prior cell, here are some things to check: <br/>\n",
    "            First, check your Spam folder! Several students have missed that the emails arrived in Spam!<br/>Second, print(result) and see if you are receiving errors about SSL. \n",
    "            If you're receiving SSL errors, then please check out theses <a href=\"https://chatgpt.com/share/680620ec-3b30-8012-8c26-ca86693d0e3d\">networking tips</a> and see the note in the next cell. Also look at the trace in OpenAI, and investigate on the SendGrid website, to hunt for clues. Let me know if I can help!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And one more suggestion to send emails from student Oleksandr on Windows 11:\n",
    "\n",
    "If you are getting certificate SSL errors, then:  \n",
    "Run this in a terminal: `uv pip install --upgrade certifi`\n",
    "\n",
    "Then run this code:\n",
    "```python\n",
    "import certifi\n",
    "import os\n",
    "os.environ['SSL_CERT_FILE'] = certifi.where()\n",
    "```\n",
    "\n",
    "Thank you Oleksandr!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remember to check the trace\n",
    "\n",
    "https://platform.openai.com/traces\n",
    "\n",
    "And then check your email!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handoffs represent a way an agent can delegate to an agent, passing control to it\n",
    "\n",
    "Handoffs and Agents-as-tools are similar:\n",
    "\n",
    "In both cases, an Agent can collaborate with another Agent\n",
    "\n",
    "With tools, control passes back\n",
    "\n",
    "With handoffs, control passes across\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subject_instructions = \"You can write a subject for a cold sales email. \\\n",
    "You are given a message and you need to write a subject for an email that is likely to get a response.\"\n",
    "\n",
    "html_instructions = \"You can convert a text email body to an HTML email body. \\\n",
    "You are given a text email body which might have some markdown \\\n",
    "and you need to convert it to an HTML email body with simple, clear, compelling layout and design.\"\n",
    "\n",
    "subject_writer = Agent(name=\"Email subject writer\", instructions=subject_instructions, model=\"gpt-4o-mini\")\n",
    "subject_tool = subject_writer.as_tool(tool_name=\"subject_writer\", tool_description=\"Write a subject for a cold sales email\")\n",
    "\n",
    "html_converter = Agent(name=\"HTML email body converter\", instructions=html_instructions, model=\"gpt-4o-mini\")\n",
    "html_tool = html_converter.as_tool(tool_name=\"html_converter\",tool_description=\"Convert a text email body to an HTML email body\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def send_html_email(subject: str, html_body: str) -> Dict[str, str]:\n",
    "    \"\"\" Send out an email with the given subject and HTML body to all sales prospects \"\"\"\n",
    "    sg = sendgrid.SendGridAPIClient(api_key=os.environ.get('SENDGRID_API_KEY'))\n",
    "    from_email = Email(\"ed@edwarddonner.com\")  # Change to your verified sender\n",
    "    to_email = To(\"ed.donner@gmail.com\")  # Change to your recipient\n",
    "    content = Content(\"text/html\", html_body)\n",
    "    mail = Mail(from_email, to_email, subject, content).get()\n",
    "    sg.client.mail.send.post(request_body=mail)\n",
    "    return {\"status\": \"success\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [subject_tool, html_tool, send_html_email]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions =\"You are an email formatter and sender. You receive the body of an email to be sent. \\\n",
    "You first use the subject_writer tool to write a subject for the email, then use the html_converter tool to convert the body to HTML. \\\n",
    "Finally, you use the send_html_email tool to send the email with the subject and HTML body.\"\n",
    "\n",
    "\n",
    "emailer_agent = Agent(\n",
    "    name=\"Email Manager\",\n",
    "    instructions=instructions,\n",
    "    tools=tools,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    handoff_description=\"Convert an email to HTML and send it\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have 3 tools and 1 handoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [tool1, tool2, tool3]\n",
    "handoffs = [emailer_agent]\n",
    "print(tools)\n",
    "print(handoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved instructions thanks to student Guillermo F.\n",
    "\n",
    "sales_manager_instructions = \"\"\"\n",
    "You are a Sales Manager at ComplAI. Your goal is to find the single best cold sales email using the sales_agent tools.\n",
    " \n",
    "Follow these steps carefully:\n",
    "1. Generate Drafts: Use all three sales_agent tools to generate three different email drafts. Do not proceed until all three drafts are ready.\n",
    " \n",
    "2. Evaluate and Select: Review the drafts and choose the single best email using your judgment of which one is most effective.\n",
    "You can use the tools multiple times if you're not satisfied with the results from the first try.\n",
    " \n",
    "3. Handoff for Sending: Pass ONLY the winning email draft to the 'Email Manager' agent. The Email Manager will take care of formatting and sending.\n",
    " \n",
    "Crucial Rules:\n",
    "- You must use the sales agent tools to generate the drafts ‚Äî do not write them yourself.\n",
    "- You must hand off exactly ONE email to the Email Manager ‚Äî never more than one.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "sales_manager = Agent(\n",
    "    name=\"Sales Manager\",\n",
    "    instructions=sales_manager_instructions,\n",
    "    tools=tools,\n",
    "    handoffs=handoffs,\n",
    "    model=\"gpt-4o-mini\")\n",
    "\n",
    "message = \"Send out a cold sales email addressed to Dear CEO from Alice\"\n",
    "\n",
    "with trace(\"Automated SDR\"):\n",
    "    result = await Runner.run(sales_manager, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remember to check the trace\n",
    "\n",
    "https://platform.openai.com/traces\n",
    "\n",
    "And then check your email!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Can you identify the Agentic design patterns that were used here?<br/>\n",
    "            What is the 1 line that changed this from being an Agentic \"workflow\" to \"agent\" under Anthropic's definition?<br/>\n",
    "            Try adding in more tools and Agents! You could have tools that handle the mail merge to send to a list.<br/><br/>\n",
    "            HARD CHALLENGE: research how you can have SendGrid call a Callback webhook when a user replies to an email,\n",
    "            Then have the SDR respond to keep the conversation going! This may require some \"vibe coding\" üòÇ\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">This is immediately applicable to Sales Automation; but more generally this could be applied to  end-to-end automation of any business process through conversations and tools. Think of ways you could apply an Agent solution\n",
    "            like this in your day job.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra note:\n",
    "\n",
    "Google has released their Agent Development Kit (ADK). It's not yet got the traction of the other frameworks on this course, but it's getting some attention. It's interesting to note that it looks quite similar to OpenAI Agents SDK. To give you a preview, here's a peak at sample code from ADK:\n",
    "\n",
    "```\n",
    "root_agent = Agent(\n",
    "    name=\"weather_time_agent\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    description=\"Agent to answer questions about the time and weather in a city.\",\n",
    "    instruction=\"You are a helpful agent who can answer user questions about the time and weather in a city.\",\n",
    "    tools=[get_weather, get_current_time]\n",
    ")\n",
    "```\n",
    "\n",
    "Well, that looks familiar!\n",
    "\n",
    "And a student has contributed a customer care agent in community_contributions that uses ADK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
